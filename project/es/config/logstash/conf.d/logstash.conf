# 参考：https://www.cnblogs.com/fnlingnzb-learner/p/16635473.html
input {
# 支持file、kafka、beats等
#     beats {
#         port => 5044
#     }
    tcp{
        port => 5044
#         codec => "json"
    }
}

filter {

# 官方文档：https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html
    grok {
        patterns_dir => ["./pattern"]
        match => [ "message", "(TIMEMILLS:timeMills)\s+\[(?<thread>.*)\]\s+(?<level>\w*)\s{1,2}+(?<class>\S*)\s+-\s+(CONTENT:message)\s*"]
#         match => [ "message", "(?<logTime>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})\s{1,2}+(?<level>\w*)\s{1,2}+.\s---+\s\[(?<thread>.*)\]+\s(?<class>\S*)\s*:+\s(?<content>.*)\s*"]
#         match => [
#         "source", "/Users/liufeng/IdeaProjects/liufeng82012016.github.io/project/es/log/(?<logName>\w+)/.*.log"
#         ]
        overwrite => [ "message"]
#         add_field => ["timeMills"]
        break_on_match => true
    }

    mutate {
        convert => {
            "bytes" => "integer"
        }
        remove_field => ["agent","@version", "ecs", "_score", "input", "[log][offset]"]
    }

    useragent {
        source => "user_agent"
        target => "useragent"
    }

    date {
        match => ["logTime", "MMM d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601"]
        timezone => "Asia/Shanghai"
    }
}
# 将数据输出到特定目的地
output {
    stdout { }

    elasticsearch {
        hosts => ["http://172.17.0.4:9200"]
        index => "elk_log"
    }
}
